{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from utils import get_image_paths, word_from_image_path, preprocess_image, print_im, TextTransform, N_CHARS, SEQUENCE_LENGTH, IMAGE_DIMENSIONS\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multi_gpu import make_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '/mnt/mnt/ramdisk/max/90kDICT32px/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_paths = get_image_paths(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_transformer = TextTransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_y = text_transformer.make_batch_labels(images_paths[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ims = [load_img(im, grayscale=True) for im in images_paths[:]]\n",
    "ims = [preprocess_image(img_to_array(im)) for im in ims]\n",
    "batch = np.array(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "batch = batch - batch.mean(axis=(1, 2)).reshape((-1, 1, 1))\n",
    "batch = batch / batch.std(axis=(1, 2)).reshape((-1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Reshape, Activation\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convolutions = [64, 128, 256, 512, 512]\n",
    "kernels = [5, 5, 3, 3, 3]\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (None,) + IMAGE_DIMENSIONS + (1,)\n",
    "\n",
    "model.add(Conv2D(nb_filter=64,\n",
    "                     nb_row=kernels[0],\n",
    "                     nb_col=kernels[0],\n",
    "                     activation='relu',\n",
    "                     border_mode='same',\n",
    "                     batch_input_shape=input_shape, name=\"convo\" + str(0)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "\n",
    "for i, (kernel, convolution_size) in enumerate(zip(convolutions[1:], kernels[1:])):\n",
    "    model.add(Conv2D(nb_filter=convolution_size,\n",
    "                     nb_row=kernel,\n",
    "                     nb_col=kernel,\n",
    "                     activation='relu',\n",
    "                     border_mode='same',\n",
    "                     name=\"convo\" + str(i + 1)))\n",
    "    \n",
    "    if i <= 3 :\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same',))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "model.add(Dense(SEQUENCE_LENGTH * N_CHARS))\n",
    "\n",
    "model.add(Reshape((SEQUENCE_LENGTH, N_CHARS)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_model = make_parallel(model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 36 ms, total: 148 ms\n",
      "Wall time: 474 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = p_model.predict(batch[32*100:32*101, :, :].reshape((batch[32*100:32*101, :, :].shape[0],) + IMAGE_DIMENSIONS+ (1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sarti                   crustal                \n",
      "sart                    paths                  \n",
      "sart                    pace                   \n",
      "sereiii                 arapahoes              \n",
      "seeeiiie                retorts                \n",
      "sereiii                 corrosively            \n",
      "sarti                   betas                  \n",
      "seeeiiii                interpenetration       \n",
      "sarte                   temps                  \n",
      "sait                    pb                     \n",
      "seeeriiin               transliteration        \n",
      "sereii                  buskin                 \n",
      "sartie                  briton                 \n",
      "seeeiii                 interacted             \n",
      "sartie                  chained                \n",
      "seeeiii                 regularizing           \n",
      "sereiii                 cadenzas               \n",
      "seeeiii                 teaspoons              \n",
      "seeeiiie                \n",
      "sartie                  overcoats              \n",
      "sartie                  eulogizes              \n",
      "seeeriiin               conformist             \n",
      "sereii                  acapulco               \n",
      "sarte                   skillet                \n",
      "sartie                  elvin                  \n",
      "seeeiii                 meritorious            \n",
      "seeeiiii                symptoms               \n",
      "sartie                  what                   \n",
      "sereie                  chattanooga            \n",
      "sartie                  napping                \n",
      "sereiii                 instabilities          \n",
      "sereiie                 soapstone              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benoitletournel/workspace/Structured-Data/utils.py:58: UserWarning: missing char\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i, by in enumerate(batch_y):\n",
    "    try:\n",
    "        print(text_transformer.word_from_matrix(res[i]), text_transformer.word_from_matrix(by))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biggest_batches = 32 * (batch.shape[0] // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = batch[:biggest_batches]\n",
    "b_y = batch_y[:biggest_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    history = p_model.fit(b.reshape((b.shape[0],) + IMAGE_DIMENSIONS + (1,)), b_y, nb_epoch=1)\n",
    "    \n",
    "    now = datetime.datetime.now().isoformat().split('.')[0]\n",
    "\n",
    "    with open(\"state\", 'a+') as f:\n",
    "        f.write(\"epoch={}, loss={}, now={}\\n\".format(epoch, history.history['loss'][0], now))\n",
    "    \n",
    "    p_model.save('p_model_{}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

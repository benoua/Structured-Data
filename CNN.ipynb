{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from utils import get_image_paths, word_from_image_path, preprocess_image, print_im, TextTransform, N_CHARS, SEQUENCE_LENGTH, IMAGE_DIMENSIONS\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multi_gpu import make_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = '/mnt/mjsynth/mnt/ramdisk/max/90kDICT32px/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 9.64 s, total: 24 s\n",
      "Wall time: 45.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "images_paths = get_image_paths(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8919273"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_transformer = TextTransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "ims = []\n",
    "errors_1, errors_2 = [], []\n",
    "for i, im in tqdm_notebook(enumerate(images_paths[:]), total=len(images_paths)):\n",
    "    try:\n",
    "        ims.append(preprocess_image(img_to_array(load_img(im, grayscale=True))))\n",
    "    except OSError:\n",
    "        errors_1.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch1 = np.array(ims[:1000000])\n",
    "ims = ims[1000000:]\n",
    "batch2 = np.array(ims[:1000000])\n",
    "one_million = 1000000\n",
    "del ims[:one_million]\n",
    "batch3 = np.array(ims[:one_million])\n",
    "del ims[:one_million]\n",
    "batch4 = np.array(ims[:one_million])\n",
    "del ims[:one_million]\n",
    "batch5 = np.array(ims[:one_million])\n",
    "del ims[:one_million]\n",
    "batch6 = np.array(ims[:one_million])\n",
    "del ims[:one_million]\n",
    "batch7 = np.array(ims[:one_million])\n",
    "del ims[:one_million]\n",
    "batch8 = np.array(ims[:one_million])\n",
    "del ims[:one_million]\n",
    "batch9 = np.array(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('/mnt/x1.py', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch1)\n",
    "with h5py.File('/mnt/x2.py', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch2)\n",
    "with h5py.File('/mnt/x3.py', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch3)\n",
    "with h5py.File('/mnt/x4.py', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch4)\n",
    "with h5py.File('/mnt/x5.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch5)\n",
    "with h5py.File('/mnt/x6.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch6)\n",
    "with h5py.File('/mnt/x7.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch7)\n",
    "with h5py.File('/mnt/x8.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch8)\n",
    "with h5py.File('/mnt/x9.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=batch9)\n",
    "with h5py.File('/mnt/errors.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=np.array(errors_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del batch1, batch2, batch3, batch4, batch5, batch6, batch7, batch8, batch9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_paths_without_errors = []\n",
    "\n",
    "for i, im in tqdm_notebook(enumerate(images_paths), total=len(images_paths)):\n",
    "    if i not in errors_1:\n",
    "        image_paths_without_errors.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 33s, sys: 3min 33s, total: 8min 7s\n",
      "Wall time: 8min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_y = text_transformer.make_batch_labels(image_paths_without_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_y = batch_y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File('/mnt/y.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x\",  data=np.array(b_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File('/mnt/errors.h5', 'r') as hf:\n",
    "    errors_1 = hf['x'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/mnt/x1.h5', 'r') as hf:\n",
    "    x1 = hf['x'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-82be2fdf48c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/x{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5, 9):\n",
    "    print(i)\n",
    "    with h5py.File('/mnt/x{}.h5'.format(i), 'r') as hf:\n",
    "        x1 = np.concatenate((x1, hf['x'][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 1min 12s, total: 1min 28s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('/mnt/x.npy', 'wb+') as f:\n",
    "    np.save(f, x1[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000000, 32, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x2 = np.concatenate((x1, x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 32, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "batch = batch - batch.mean(axis=(1, 2)).reshape((-1, 1, 1))\n",
    "batch = batch / batch.std(axis=(1, 2)).reshape((-1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data (remove errors from y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/mnt/y.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"y\",  data=batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Reshape, Activation\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import IMAGE_DIMENSIONS, SEQUENCE_LENGTH, N_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "convolutions = [64, 128, 256, 512, 512]\n",
    "kernels = [5, 5, 3, 3, 3]\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (None,) + IMAGE_DIMENSIONS + (1,)\n",
    "\n",
    "model.add(Conv2D(nb_filter=64,\n",
    "                     nb_row=kernels[0],\n",
    "                     nb_col=kernels[0],\n",
    "                     activation='relu',\n",
    "                     border_mode='same',\n",
    "                     batch_input_shape=input_shape, name=\"convo\" + str(0)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "\n",
    "for i, (kernel, convolution_size) in enumerate(zip(convolutions[1:], kernels[1:])):\n",
    "    model.add(Conv2D(nb_filter=convolution_size,\n",
    "                     nb_row=kernel,\n",
    "                     nb_col=kernel,\n",
    "                     activation='relu',\n",
    "                     border_mode='same',\n",
    "                     name=\"convo\" + str(i + 1)))\n",
    "    \n",
    "    if i <= 3 :\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same',))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "model.add(Dense(SEQUENCE_LENGTH * N_CHARS))\n",
    "\n",
    "model.add(Reshape((SEQUENCE_LENGTH, N_CHARS)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_model = make_parallel(model, 4)\n",
    "p_model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_random_weights.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biggest_batches = 32 * (batch.shape[0] // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = batch[:biggest_batches]\n",
    "b_y = batch_y[:biggest_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    history = p_model.fit(b.reshape((b.shape[0],) + IMAGE_DIMENSIONS + (1,)), b_y, nb_epoch=1)\n",
    "    \n",
    "    now = datetime.datetime.now().isoformat().split('.')[0]\n",
    "\n",
    "    with open(\"state\", 'a+') as f:\n",
    "        f.write(\"epoch={}, loss={}, now={}\\n\".format(epoch, history.history['loss'][0], now))\n",
    "    \n",
    "    p_model.save('p_model_{}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sarti                   crustal                \n",
      "sart                    paths                  \n",
      "sart                    pace                   \n",
      "sereiii                 arapahoes              \n",
      "seeeiiie                retorts                \n",
      "sereiii                 corrosively            \n",
      "sarti                   betas                  \n",
      "seeeiiii                interpenetration       \n",
      "sarte                   temps                  \n",
      "sait                    pb                     \n",
      "seeeriiin               transliteration        \n",
      "sereii                  buskin                 \n",
      "sartie                  briton                 \n",
      "seeeiii                 interacted             \n",
      "sartie                  chained                \n",
      "seeeiii                 regularizing           \n",
      "sereiii                 cadenzas               \n",
      "seeeiii                 teaspoons              \n",
      "seeeiiie                \n",
      "sartie                  overcoats              \n",
      "sartie                  eulogizes              \n",
      "seeeriiin               conformist             \n",
      "sereii                  acapulco               \n",
      "sarte                   skillet                \n",
      "sartie                  elvin                  \n",
      "seeeiii                 meritorious            \n",
      "seeeiiii                symptoms               \n",
      "sartie                  what                   \n",
      "sereie                  chattanooga            \n",
      "sartie                  napping                \n",
      "sereiii                 instabilities          \n",
      "sereiie                 soapstone              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benoitletournel/workspace/Structured-Data/utils.py:58: UserWarning: missing char\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i, by in enumerate(batch_y):\n",
    "    try:\n",
    "        print(text_transformer.word_from_matrix(res[i]), text_transformer.word_from_matrix(by))\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "4a43e4e64eb643c39c4614919ac18981": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "743f63b37aeb44d79d977b8f42ac7ca4": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
